# ðŸš€ Conda Environment Setup for LangChain

## ðŸ“Œ Step 1: Install Python 3.11 Using Conda
```bash
conda create -n langchain_env python=3.11
```
ðŸ”¹ This creates a new Conda environment named `langchain_env` with **Python 3.11**.

## ðŸ“Œ Step 2: Activate the Conda Environment
```bash
conda activate langchain_env
```
ðŸ”¹ Always run this command before working on a LangChain app.

## ðŸ“Œ Step 3: Install LangChain and Dependencies
```bash
pip install langchain openai faiss-cpu python-dotenv pipreqs
```
ðŸ”¹ **Packages:**
- `langchain` â†’ AI framework
- `openai` â†’ OpenAI API support
- `faiss-cpu` â†’ Vector search (use `faiss-gpu` if on a compatible system)
- `python-dotenv` â†’ Manage API keys
- `pipreqs` â†’ Auto-generate `requirements.txt` with only necessary dependencies

## ðŸ“Œ Step 4: Create a New Project Folder
```bash
mkdir my_langchain_app && cd my_langchain_app
```
ðŸ”¹ This keeps your LangChain apps organized.

## ðŸ“Œ Step 5: Create a Python Script (`app.py`)
```bash
touch app.py
```
ðŸ”¹ Open it in VS Code:
```bash
code app.py
```

## ðŸ“Œ Step 6: Write a Simple LangChain App

ðŸ”¹ **Important Note on Deprecation:**
Recent LangChain updates have changed how models are imported. If you see warnings about deprecated imports, update your code to use `langchain_openai` instead of `langchain`. The `OpenAI` class for chat models has also been moved to `ChatOpenAI`.

Paste this into `app.py`:
```python
# âœ… New (Correct Import)
from langchain_openai import ChatOpenAI

import os
from dotenv import load_dotenv

# Load environment variables
load_dotenv()
api_key = os.getenv("OPENAI_API_KEY")

# Initialize OpenAI model
llm = ChatOpenAI(model_name="gpt-4", openai_api_key=api_key)

# Simple chatbot
while True:
    query = input("You: ")
    if query.lower() in ["exit", "quit"]:
        print("Goodbye!")
        break
    response = llm.invoke(query)
    print("AI:", response.content)
```

## ðŸ“Œ Step 7: Generate a Clean `requirements.txt`
```bash
pipreqs . --force
```
ðŸ”¹ This creates a minimal `requirements.txt` containing only necessary dependencies.

## ðŸ“Œ Step 8: Run Your LangChain App
```bash
python app.py
```
ðŸ”¹ This will execute the script inside the Conda environment.

## ðŸ“Œ Step 9: Deactivate Conda When Done
```bash
conda deactivate
```
ðŸ”¹ This exits the Conda environment and returns to the system's default Python.

---

## ðŸ’¡ Enhancing Your Chatbot with Memory
If you want your chatbot to **remember past interactions**, you can add memory capabilities. Here are some options:

### ðŸ”¹ **Short-Term Memory (In-Memory Storage)**
- Use `ConversationBufferMemory` from LangChain to store recent messages in memory.
- Data is lost when the script stops.

**Example:**
```python
from langchain.memory import ConversationBufferMemory
memory = ConversationBufferMemory()
```

### ðŸ”¹ **Long-Term Memory (Database or Vector Storage)**
- Store conversation history in **SQLite, PostgreSQL, or MongoDB**.
- Use **Pinecone or FAISS** for vector-based retrieval.

**Example:**
```python
from langchain.memory import ConversationSummaryBufferMemory
memory = ConversationSummaryBufferMemory(llm=llm, max_token_limit=100)
```

### ðŸ”¹ **When to Use Memory?**
- If you want **conversational context** (like remembering past questions).
- If youâ€™re building a **customer support AI** or an **AI assistant**.

---

## ðŸ”” Important: Handling LangChain Deprecation Warnings
- If you see warnings like `Importing LLMs from langchain is deprecated`, ensure you're using `from langchain_openai import ChatOpenAI`.
- The `OpenAI` class should be used only for non-chat models. For chat models, use `ChatOpenAI`.
- Always keep `langchain_openai` updated using:
  ```bash
  pip install -U langchain_openai
  ```

## ðŸŽ¯ Summary: Conda Workflow for LangChain
| **Task** | **Command** |
|----------|------------|
| **Create Conda Env** | `conda create -n langchain_env python=3.11` |
| **Activate Conda Env** | `conda activate langchain_env` |
| **Install Dependencies** | `pip install langchain openai faiss-cpu python-dotenv pipreqs` |
| **Create Project Folder** | `mkdir my_langchain_app && cd my_langchain_app` |
| **Create Script** | `touch app.py && code app.py` |
| **Generate Clean `requirements.txt`** | `pipreqs . --force` |
| **Run LangChain App** | `python app.py` |
| **Exit Conda Env** | `conda deactivate` |

ðŸš€ Now you're ready to build LangChain-powered AI apps with Conda! ðŸŽ‰
